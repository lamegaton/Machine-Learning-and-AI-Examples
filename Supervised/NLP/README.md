# Introduction

## Things that I have tried



## 



# Reading List
This is a place I put all the information that I don't have time to compile them into one article yet. 

Information is growing day by day, sometimes, I feel overwhelm with it; however, good source will stay through out years. Ars longa, vita brevis.


1. Tokenizer: breaks down sentences into numerical value; however, it does not mean anything before applying those to embedding layer

https://simonwillison.net/2023/Jun/8/gpt-tokenizers/

